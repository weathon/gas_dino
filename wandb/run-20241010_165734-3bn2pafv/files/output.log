/home/wg25r/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:216: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
Val loss 0.9954613400133032 Val iou tensor(0.0071, device='cuda:0')
Traceback (most recent call last):
  File "/home/wg25r/gas_dino/main.py", line 293, in <module>
    pred = mymodel(X[:,:3], X[:,3:6], X[:,6:])
  File "/home/wg25r/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/wg25r/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/wg25r/gas_dino/main.py", line 211, in forward
    short_bg = self.backbone.get_intermediate_layers(short_bg)[0][:,1:,:]
  File "/home/wg25r/.cache/torch/hub/facebookresearch_dino_main/vision_transformer.py", line 230, in get_intermediate_layers
    x = blk(x)
  File "/home/wg25r/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/wg25r/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/wg25r/.cache/torch/hub/facebookresearch_dino_main/vision_transformer.py", line 108, in forward
    y, attn = self.attn(self.norm1(x))
  File "/home/wg25r/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/wg25r/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/wg25r/.cache/torch/hub/facebookresearch_dino_main/vision_transformer.py", line 85, in forward
    attn = (q @ k.transpose(-2, -1)) * self.scale
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacity of 47.53 GiB of which 1.02 GiB is free. Including non-PyTorch memory, this process has 46.49 GiB memory in use. Of the allocated memory 44.86 GiB is allocated by PyTorch, and 1.32 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/home/wg25r/gas_dino/main.py", line 293, in <module>
    pred = mymodel(X[:,:3], X[:,3:6], X[:,6:])
  File "/home/wg25r/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/wg25r/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/wg25r/gas_dino/main.py", line 211, in forward
    short_bg = self.backbone.get_intermediate_layers(short_bg)[0][:,1:,:]
  File "/home/wg25r/.cache/torch/hub/facebookresearch_dino_main/vision_transformer.py", line 230, in get_intermediate_layers
    x = blk(x)
  File "/home/wg25r/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/wg25r/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/wg25r/.cache/torch/hub/facebookresearch_dino_main/vision_transformer.py", line 108, in forward
    y, attn = self.attn(self.norm1(x))
  File "/home/wg25r/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/wg25r/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/wg25r/.cache/torch/hub/facebookresearch_dino_main/vision_transformer.py", line 85, in forward
    attn = (q @ k.transpose(-2, -1)) * self.scale
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacity of 47.53 GiB of which 1.02 GiB is free. Including non-PyTorch memory, this process has 46.49 GiB memory in use. Of the allocated memory 44.86 GiB is allocated by PyTorch, and 1.32 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
