{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 2, 128, 128])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "import os\n",
    "import os \n",
    "# backbone = SegformerForSemanticSegmentation.from_pretrained(\"nvidia/segformer-b1-finetuned-ade-512-512\")\n",
    "from transformers.models.segformer import TwoStreamSegformerEncoder, SegformerConfig, TwoStreamSegformerModel, TwoStreamSegformerForSemanticSegmentation\n",
    "TwoStreamSegformerForSemanticSegmentation.from_pretrained(\"nvidia/segformer-b1-finetuned-ade-512-512\")\n",
    "\n",
    "TwoStreamSegformerForSemanticSegmentation(SegformerConfig())(torch.zeros(5, 3, 512, 512), torch.zeros(5, 3, 512, 512), torch.zeros(5, 3, 512, 512)).logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of TwoStreamSegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/segformer-b1-finetuned-ade-512-512 and are newly initialized: ['segformer.encoder.BCAs.0.linear1.bias', 'segformer.encoder.BCAs.0.linear1.weight', 'segformer.encoder.BCAs.0.linear2.bias', 'segformer.encoder.BCAs.0.linear2.weight', 'segformer.encoder.BCAs.0.norm1.bias', 'segformer.encoder.BCAs.0.norm1.weight', 'segformer.encoder.BCAs.0.norm2.bias', 'segformer.encoder.BCAs.0.norm2.weight', 'segformer.encoder.BCAs.0.self_attn.in_proj_bias', 'segformer.encoder.BCAs.0.self_attn.in_proj_weight', 'segformer.encoder.BCAs.0.self_attn.out_proj.bias', 'segformer.encoder.BCAs.0.self_attn.out_proj.weight', 'segformer.encoder.BCAs.1.linear1.bias', 'segformer.encoder.BCAs.1.linear1.weight', 'segformer.encoder.BCAs.1.linear2.bias', 'segformer.encoder.BCAs.1.linear2.weight', 'segformer.encoder.BCAs.1.norm1.bias', 'segformer.encoder.BCAs.1.norm1.weight', 'segformer.encoder.BCAs.1.norm2.bias', 'segformer.encoder.BCAs.1.norm2.weight', 'segformer.encoder.BCAs.1.self_attn.in_proj_bias', 'segformer.encoder.BCAs.1.self_attn.in_proj_weight', 'segformer.encoder.BCAs.1.self_attn.out_proj.bias', 'segformer.encoder.BCAs.1.self_attn.out_proj.weight', 'segformer.encoder.BCAs.2.linear1.bias', 'segformer.encoder.BCAs.2.linear1.weight', 'segformer.encoder.BCAs.2.linear2.bias', 'segformer.encoder.BCAs.2.linear2.weight', 'segformer.encoder.BCAs.2.norm1.bias', 'segformer.encoder.BCAs.2.norm1.weight', 'segformer.encoder.BCAs.2.norm2.bias', 'segformer.encoder.BCAs.2.norm2.weight', 'segformer.encoder.BCAs.2.self_attn.in_proj_bias', 'segformer.encoder.BCAs.2.self_attn.in_proj_weight', 'segformer.encoder.BCAs.2.self_attn.out_proj.bias', 'segformer.encoder.BCAs.2.self_attn.out_proj.weight', 'segformer.encoder.BCAs.3.linear1.bias', 'segformer.encoder.BCAs.3.linear1.weight', 'segformer.encoder.BCAs.3.linear2.bias', 'segformer.encoder.BCAs.3.linear2.weight', 'segformer.encoder.BCAs.3.norm1.bias', 'segformer.encoder.BCAs.3.norm1.weight', 'segformer.encoder.BCAs.3.norm2.bias', 'segformer.encoder.BCAs.3.norm2.weight', 'segformer.encoder.BCAs.3.self_attn.in_proj_bias', 'segformer.encoder.BCAs.3.self_attn.in_proj_weight', 'segformer.encoder.BCAs.3.self_attn.out_proj.bias', 'segformer.encoder.BCAs.3.self_attn.out_proj.weight', 'segformer.encoder.BCAs.4.linear1.bias', 'segformer.encoder.BCAs.4.linear1.weight', 'segformer.encoder.BCAs.4.linear2.bias', 'segformer.encoder.BCAs.4.linear2.weight', 'segformer.encoder.BCAs.4.norm1.bias', 'segformer.encoder.BCAs.4.norm1.weight', 'segformer.encoder.BCAs.4.norm2.bias', 'segformer.encoder.BCAs.4.norm2.weight', 'segformer.encoder.BCAs.4.self_attn.in_proj_bias', 'segformer.encoder.BCAs.4.self_attn.in_proj_weight', 'segformer.encoder.BCAs.4.self_attn.out_proj.bias', 'segformer.encoder.BCAs.4.self_attn.out_proj.weight', 'segformer.encoder.BCAs.5.linear1.bias', 'segformer.encoder.BCAs.5.linear1.weight', 'segformer.encoder.BCAs.5.linear2.bias', 'segformer.encoder.BCAs.5.linear2.weight', 'segformer.encoder.BCAs.5.norm1.bias', 'segformer.encoder.BCAs.5.norm1.weight', 'segformer.encoder.BCAs.5.norm2.bias', 'segformer.encoder.BCAs.5.norm2.weight', 'segformer.encoder.BCAs.5.self_attn.in_proj_bias', 'segformer.encoder.BCAs.5.self_attn.in_proj_weight', 'segformer.encoder.BCAs.5.self_attn.out_proj.bias', 'segformer.encoder.BCAs.5.self_attn.out_proj.weight', 'segformer.encoder.BCAs.6.linear1.bias', 'segformer.encoder.BCAs.6.linear1.weight', 'segformer.encoder.BCAs.6.linear2.bias', 'segformer.encoder.BCAs.6.linear2.weight', 'segformer.encoder.BCAs.6.norm1.bias', 'segformer.encoder.BCAs.6.norm1.weight', 'segformer.encoder.BCAs.6.norm2.bias', 'segformer.encoder.BCAs.6.norm2.weight', 'segformer.encoder.BCAs.6.self_attn.in_proj_bias', 'segformer.encoder.BCAs.6.self_attn.in_proj_weight', 'segformer.encoder.BCAs.6.self_attn.out_proj.bias', 'segformer.encoder.BCAs.6.self_attn.out_proj.weight', 'segformer.encoder.BCAs.7.linear1.bias', 'segformer.encoder.BCAs.7.linear1.weight', 'segformer.encoder.BCAs.7.linear2.bias', 'segformer.encoder.BCAs.7.linear2.weight', 'segformer.encoder.BCAs.7.norm1.bias', 'segformer.encoder.BCAs.7.norm1.weight', 'segformer.encoder.BCAs.7.norm2.bias', 'segformer.encoder.BCAs.7.norm2.weight', 'segformer.encoder.BCAs.7.self_attn.in_proj_bias', 'segformer.encoder.BCAs.7.self_attn.in_proj_weight', 'segformer.encoder.BCAs.7.self_attn.out_proj.bias', 'segformer.encoder.BCAs.7.self_attn.out_proj.weight', 'segformer.encoder.test.bias', 'segformer.encoder.test.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TwoStreamSegformerForSemanticSegmentation(\n",
       "  (segformer): TwoStreamSegformerModel(\n",
       "    (encoder): TwoStreamSegformerEncoder(\n",
       "      (patch_embeddings): ModuleList(\n",
       "        (0): SegformerOverlapPatchEmbeddings(\n",
       "          (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))\n",
       "          (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): SegformerOverlapPatchEmbeddings(\n",
       "          (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): SegformerOverlapPatchEmbeddings(\n",
       "          (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): SegformerOverlapPatchEmbeddings(\n",
       "          (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (block): ModuleList(\n",
       "        (0): ModuleList(\n",
       "          (0): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=64, out_features=64, bias=True)\n",
       "                (key): Linear(in_features=64, out_features=64, bias=True)\n",
       "                (value): Linear(in_features=64, out_features=64, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))\n",
       "                (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=64, out_features=64, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "            (layer_norm_2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=64, out_features=256, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=256, out_features=64, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=64, out_features=64, bias=True)\n",
       "                (key): Linear(in_features=64, out_features=64, bias=True)\n",
       "                (value): Linear(in_features=64, out_features=64, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))\n",
       "                (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=64, out_features=64, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.014285714365541935)\n",
       "            (layer_norm_2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=64, out_features=256, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=256, out_features=64, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): ModuleList(\n",
       "          (0): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "                (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.02857142873108387)\n",
       "            (layer_norm_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "                (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.04285714402794838)\n",
       "            (layer_norm_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): ModuleList(\n",
       "          (0): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (key): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (value): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.05714285746216774)\n",
       "            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (key): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (value): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.0714285746216774)\n",
       "            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): ModuleList(\n",
       "          (0): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.08571428805589676)\n",
       "            (layer_norm_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.10000000149011612)\n",
       "            (layer_norm_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (BCAs): ModuleList(\n",
       "        (0-1): 2 x TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
       "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (2-3): 2 x TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=128, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=128, bias=True)\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (4-5): 2 x TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=320, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=320, bias=True)\n",
       "          (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (6-7): 2 x TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): ModuleList(\n",
       "        (0): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (test): Linear(in_features=256, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (decode_head): SegformerDecodeHead(\n",
       "    (linear_c): ModuleList(\n",
       "      (0): SegformerMLP(\n",
       "        (proj): Linear(in_features=64, out_features=256, bias=True)\n",
       "      )\n",
       "      (1): SegformerMLP(\n",
       "        (proj): Linear(in_features=128, out_features=256, bias=True)\n",
       "      )\n",
       "      (2): SegformerMLP(\n",
       "        (proj): Linear(in_features=320, out_features=256, bias=True)\n",
       "      )\n",
       "      (3): SegformerMLP(\n",
       "        (proj): Linear(in_features=512, out_features=256, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (linear_fuse): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (batch_norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activation): ReLU()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (classifier): Conv2d(256, 150, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TwoStreamSegformerForSemanticSegmentation.from_pretrained(\"nvidia/segformer-b1-finetuned-ade-512-512\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1,  2,  3],\n",
       "        [ 4,  5,  6]],\n",
       "\n",
       "       [[11,  2,  3],\n",
       "        [ 4,  5,  6]],\n",
       "\n",
       "       [[ 7,  8,  9],\n",
       "        [10, 11, 12]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "x = np.array(\n",
    "    [[[1, 2, 3],[4, 5, 6]],[[11, 2, 3],[4, 5, 6]], [[7, 8, 9],[10, 11, 12]]]\n",
    ")\n",
    "y = np.array(\n",
    "    [[[-1, -2, -3],[-4, -5, -6]],[[-11, -2, -3],[-4, -5, -6]], [[-7, -8, -9],[-10, -11, -12]]]\n",
    ")\n",
    "z = np.concatenate([x, y], axis=0)\n",
    "z.shape\n",
    "z.reshape(2, 3, 2, 3)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backbone.segformer.encoder.patch_embeddings[0].proj = torch.nn.Conv2d(9, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))\n",
    "backbone.segformer.encoder.block[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "backbone2 = SegformerForSemanticSegmentation.from_pretrained(\"nvidia/segformer-b1-finetuned-ade-512-512\")\n",
    "class BCA(nn.Module):\n",
    "    \"\"\"\n",
    "    Background-CurrentFrame Attention\n",
    "    \"\"\"\n",
    "    def __init__(self, dim=384):\n",
    "        super(BCA, self).__init__()\n",
    "        self.dim = dim\n",
    "        self.key_projection = nn.Linear(dim, dim)\n",
    "        self.query_projection = nn.Linear(dim, dim)\n",
    "        self.value_projection = nn.Linear(dim * 2, dim)\n",
    "        self.projection_dropout = nn.Dropout(0.2)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(2 * dim, 1024),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.Dropout(0.2), \n",
    "            nn.ReLU(), \n",
    "            nn.Linear(1024, dim),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "        self.norm1 = nn.LayerNorm(dim) \n",
    "        self.norm2 = nn.LayerNorm(dim)\n",
    "        self.head = nn.Linear(dim * 2, dim)\n",
    "\n",
    "    def forward(self, current_frame, long_background, short_background):\n",
    "        \"\"\"\n",
    "        long_background: torch.Tensor, shape (batch, L, dim)\n",
    "        short_background: torch.Tensor, shape (batch, L, dim)\n",
    "        current_frame: torch.Tensor, shape (batch, L, dim)\n",
    "        \"\"\"\n",
    "        key = self.projection_dropout(self.key_projection(long_background))\n",
    "        query = self.projection_dropout(self.query_projection(current_frame))\n",
    "        value = self.projection_dropout(self.value_projection(torch.concatenate([long_background, current_frame], dim=-1)))\n",
    "\n",
    "        attn_score = torch.einsum(\"bld,bld->bl\", query, key) / self.dim**0.5\n",
    "        attn_score = F.softmax(attn_score, dim=1)\n",
    "        attn_output = torch.einsum(\"bl,bld->bld\", attn_score, value)\n",
    "        attn_output = self.norm1(attn_output + current_frame) \n",
    "        mlp_output = self.mlp(torch.concatenate([attn_output, current_frame], dim=-1))\n",
    "        mlp_output = self.norm2(mlp_output + attn_output)\n",
    "\n",
    "        # short background attention with frame\n",
    "        key = self.projection_dropout(self.key_projection(short_background))\n",
    "        query = self.projection_dropout(self.query_projection(current_frame))\n",
    "        value = self.projection_dropout(self.value_projection(torch.concatenate([short_background, current_frame], dim=-1)))\n",
    "\n",
    "        attn_score = torch.einsum(\"bld,bld->bl\", query, key) / self.dim**0.5\n",
    "        attn_score = F.softmax(attn_score, dim=1)\n",
    "        attn_output = torch.einsum(\"bl,bld->bld\", attn_score, value) \n",
    "        attn_output = self.norm1(attn_output + mlp_output)\n",
    "        mlp_output = self.mlp(torch.concatenate([attn_output, mlp_output], dim=-1))\n",
    "        mlp_output2 = self.norm2(mlp_output + attn_output)\n",
    "        return self.head(torch.cat([mlp_output, mlp_output2], dim=-1))\n",
    "        \n",
    "class NewSegformerLayer(torch.nn.Module):\n",
    "    def __init__(self, original_layer):\n",
    "        super().__init__()\n",
    "        self.original_layer = original_layer\n",
    "        self.bca = BCA()\n",
    "\n",
    "    def forward(self, hidden_states, height, width, output_attention):\n",
    "        x = self.original_layer(hidden_states, height, width, output_attention)\n",
    "        print(len(x))\n",
    "        return self.new(x)\n",
    "    \n",
    "backbone2.segformer.encoder.block[0][0] = NewSegformerLayer(backbone.segformer.encoder.block[0][0])\n",
    "rand_x = torch.randn(64, 3, 256, 256)\n",
    "assert not torch.allclose(backbone(rand_x).logits, backbone2(rand_x).logits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
